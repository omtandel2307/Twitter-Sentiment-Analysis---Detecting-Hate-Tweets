{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "J335vVnqo_ic"
      },
      "outputs": [],
      "source": [
        "import numpy as np \n",
        "import pandas as pd \n",
        "import matplotlib.pyplot as plt \n",
        "import seaborn as sns\n",
        "from sklearn import datasets \n",
        "from sklearn.linear_model import LogisticRegression \n",
        "from sklearn.model_selection import train_test_split \n",
        "from sklearn.metrics import accuracy_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "7fjvG2KZpBdA",
        "outputId": "dfec688c-d884-4611-bd29-dfd67699b81b"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>class</th>\n",
              "      <th>tweet</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>RT @__Junebugg: @VoiceOfDStreetz hell yea save...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>How the hell was David Murphy's hit not a home...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>RT @FeeelGreatness: You don't know where your ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>Thats some hoe shit doe</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2</td>\n",
              "      <td>I just want vanilla Oreos</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19821</th>\n",
              "      <td>1</td>\n",
              "      <td>RT @davegetnmoney: I beat the pussy up up up u...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19822</th>\n",
              "      <td>2</td>\n",
              "      <td>RT @RT_America: Russell Brand mocks Bill O'Rei...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19823</th>\n",
              "      <td>1</td>\n",
              "      <td>@_B_R_Y_C_E_ what happened to going fishing bi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19824</th>\n",
              "      <td>2</td>\n",
              "      <td>RT @BriannDominguez: Gasoline - daddy Yankee &amp;...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19825</th>\n",
              "      <td>1</td>\n",
              "      <td>RT @LowkeyStoner_: Gay girls really do get mor...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>19826 rows Ã— 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       class                                              tweet\n",
              "0          1  RT @__Junebugg: @VoiceOfDStreetz hell yea save...\n",
              "1          2  How the hell was David Murphy's hit not a home...\n",
              "2          1  RT @FeeelGreatness: You don't know where your ...\n",
              "3          1                            Thats some hoe shit doe\n",
              "4          2                          I just want vanilla Oreos\n",
              "...      ...                                                ...\n",
              "19821      1  RT @davegetnmoney: I beat the pussy up up up u...\n",
              "19822      2  RT @RT_America: Russell Brand mocks Bill O'Rei...\n",
              "19823      1  @_B_R_Y_C_E_ what happened to going fishing bi...\n",
              "19824      2  RT @BriannDominguez: Gasoline - daddy Yankee &...\n",
              "19825      1  RT @LowkeyStoner_: Gay girls really do get mor...\n",
              "\n",
              "[19826 rows x 2 columns]"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df = pd.read_csv('hate_speech_data_train.csv') \n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-HfM7SPApCdu",
        "outputId": "93a4fd93-6d81-470d-e3d3-9b75b7db4b4f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(19826, 2)"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DdL1rvXCpDTN",
        "outputId": "bd045e85-6fae-4cc0-efb0-845b8f9ea901"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 19826 entries, 0 to 19825\n",
            "Data columns (total 2 columns):\n",
            " #   Column  Non-Null Count  Dtype \n",
            "---  ------  --------------  ----- \n",
            " 0   class   19826 non-null  int64 \n",
            " 1   tweet   19826 non-null  object\n",
            "dtypes: int64(1), object(1)\n",
            "memory usage: 309.9+ KB\n"
          ]
        }
      ],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HORNDPoLpEVB",
        "outputId": "5f7d53bb-ace7-4af4-f344-9c6850c1cab3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "class    0\n",
              "tweet    0\n",
              "dtype: int64"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_KoyoPaSpHc4",
        "outputId": "e8d7e6a8-6987-44b4-b06e-402ad303eff8"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     C:\\Users\\tande\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "import re\n",
        "\n",
        "nltk.download('stopwords')\n",
        "port_stem=PorterStemmer()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mgnGWVC1pI0g",
        "outputId": "906f00e5-657b-4055-ae5b-791db4236172"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<PorterStemmer>"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "port_stem"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "rYM9XTf-pKCs",
        "outputId": "8aad5b17-7955-4288-af68-35e447b4877d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'hi this is crimson  * % %@@@'"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "port_stem.stem(\"Hi thIs is crimson  * % %@@@\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "WVUHwBqEpLK6"
      },
      "outputs": [],
      "source": [
        "def stemming(content):\n",
        "    con=re.sub('[^a-zA-Z]', ' ', content)\n",
        "    con=con.lower()\n",
        "    con=con.split()\n",
        "    con=[port_stem.stem(word) for word in con if not word in stopwords.words('english')]\n",
        "    con=' '.join(con)\n",
        "    return con"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "gLgh0luZpMLq"
      },
      "outputs": [],
      "source": [
        "df['tweet']= df['tweet'].apply(stemming)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "7aI0WzEupNMl"
      },
      "outputs": [],
      "source": [
        "X = df['tweet']\n",
        "Y = df['class']\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l523lSumpOTC",
        "outputId": "daef6c04-ab93-4c02-927f-e9b7042c2724"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(19826,)"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Aj03KzTpPvY",
        "outputId": "752f1b0c-4ae9-46c1-a740-aeb23d567d28"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(15860,)\n",
            "(3966,)\n"
          ]
        }
      ],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
        "\n",
        "print(X_train.shape)\n",
        "print(X_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "GZOUEigQ18Sn"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading the Word2Vec model...\n",
            "Model downloaded successfully!\n",
            "Model saved to 'word2vec_model.pkl' successfully!\n",
            "Model loaded from 'word2vec_model.pkl' successfully!\n"
          ]
        }
      ],
      "source": [
        "# import pandas as pd\n",
        "# import numpy as np\n",
        "# import pickle\n",
        "# import gensim.downloader as api\n",
        "# from sklearn.feature_extraction.text import CountVectorizer\n",
        "# from sklearn.tree import DecisionTreeClassifier\n",
        "# from sklearn.metrics import classification_report\n",
        "\n",
        "# # Load the pre-trained Word2Vec model\n",
        "# model = api.load(\"word2vec-google-news-300\")\n",
        "\n",
        "# model = pickle.load(open('word2vec_model.pkl', 'rb'))\n",
        "\n",
        "\n",
        "# # Save the model to a file using pickle\n",
        "# with open('word2vec_model.pkl', 'wb') as f:\n",
        "#     pickle.dump(model, f)\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import pickle\n",
        "import gensim.downloader as api\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Step 1: Load the pre-trained Word2Vec model using gensim\n",
        "print(\"Downloading the Word2Vec model...\")\n",
        "model = api.load(\"word2vec-google-news-300\")\n",
        "print(\"Model downloaded successfully!\")\n",
        "\n",
        "# Step 2: Save the model to a file using pickle\n",
        "with open('word2vec_model.pkl', 'wb') as f:\n",
        "    pickle.dump(model, f)\n",
        "print(\"Model saved to 'word2vec_model.pkl' successfully!\")\n",
        "\n",
        "# Step 3: Load the model from the file (later when needed)\n",
        "# You can comment out this block if you are just saving the model\n",
        "with open('word2vec_model.pkl', 'rb') as f:\n",
        "    loaded_model = pickle.load(f)\n",
        "print(\"Model loaded from 'word2vec_model.pkl' successfully!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "ELCO-oZmpQVQ"
      },
      "outputs": [],
      "source": [
        "import numpy as np \n",
        "\n",
        "# Define a function to convert a tweet into a vector using Word2Vec\n",
        "def tweet_to_vector(tweet):\n",
        "    words = tweet.split()\n",
        "    vectors = []\n",
        "    for word in words:\n",
        "        try:\n",
        "            vectors.append(model[word])\n",
        "        except KeyError:\n",
        "            # Ignore out-of-vocabulary words\n",
        "            pass\n",
        "    if len(vectors) > 0:\n",
        "        return np.mean(vectors, axis=0)\n",
        "    else:\n",
        "        return np.zeros(model.vector_size)\n",
        "\n",
        "# Convert the training and testing tweets to vectors using Word2Vec\n",
        "x_train = np.array([tweet_to_vector(tweet) for tweet in X_train])\n",
        "x_test = np.array([tweet_to_vector(tweet) for tweet in X_test])\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2dcj6Ip64oun",
        "outputId": "5d81d07a-9624-43e2-e669-d0d21b2aa6a1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.7481089258698941"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.linear_model import LogisticRegression \n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier \n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.naive_bayes import GaussianNB \n",
        "from sklearn.svm import SVC \n",
        "\n",
        "model2=DecisionTreeClassifier()\n",
        "model2.fit(x_train, y_train)\n",
        "prediction=model2.predict(x_test)\n",
        "prediction\n",
        "model2.score(x_test, y_test)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "QEOJBj5WQK_i"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "\n",
        "# with open('word2vec_model.pkl', 'wb') as f:\n",
        "#     pickle.dump(model, f)\n",
        "\n",
        "with open('model.pkl', 'wb') as f:\n",
        "    pickle.dump(model2, f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "6wBRTWu4QPFv"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "\n",
        "def predict_hate_speech(model_path, tweet):\n",
        "    # Load the trained model\n",
        "    with open(model_path, 'rb') as f:\n",
        "        model2 = pickle.load(f)\n",
        "    # Convert the tweet to a Word2Vec vector\n",
        "    vector = tweet_to_vector(tweet)\n",
        "    # Make the prediction\n",
        "    prediction = model2.predict(vector.reshape(1, -1))\n",
        "    if prediction==[0]:\n",
        "      print('not offensive')\n",
        "    elif prediction==[1]:\n",
        "      print('offensive')\n",
        "    else:\n",
        "      print('hate')\n",
        "      "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xC_d3qvxQ7qU",
        "outputId": "1287f0b6-4b83-4009-c000-dea467006851"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "hate\n"
          ]
        }
      ],
      "source": [
        "tweet = \"Love is in the air\"\n",
        "model_path = \"model.pkl\"\n",
        "prediction = predict_hate_speech(model_path, tweet)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h4Yy3M9RXgwc",
        "outputId": "1a86b20f-ae89-4c01-fbe1-697586e07bd4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "hate\n"
          ]
        }
      ],
      "source": [
        "tweet = \"RT @Talkmaster: People who would vote for Charlie Crist and Michelle Nunn are why our founders did NOT put a right to vote in our Constitut &#8230;\"\n",
        "model_path = \"model.pkl\"\n",
        "prediction = predict_hate_speech(model_path, tweet)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D5PnZMWSXmOC",
        "outputId": "6dbbd3ac-9d27-4b10-b1f1-fb6e01cbc6e5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "not offensive\n"
          ]
        }
      ],
      "source": [
        "tweet = \"It is a good day  whatsoever\"\n",
        "model_path = \"model.pkl\"\n",
        "prediction = predict_hate_speech(model_path, tweet)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ptZGWsr0nKOm",
        "outputId": "f8eef2a3-0f45-4e53-cedf-b985b1ab623f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "offensive\n"
          ]
        }
      ],
      "source": [
        "tweet = \"@NorahODonnell dishing Texas trash talking pts with racist @jdickerson maybe if GBush had apologize for all his sins he wouldn't be hiding and I fucking hate this fucking neighborhood\"\n",
        "model_path = \"model.pkl\"\n",
        "prediction = predict_hate_speech(model_path, tweet)\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
